{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fda40bf6b852890",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Notebook purpose\n",
    "This notebook is used to prepare the data that will later be used in our analysis of the network in R."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 57,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   "id": "a525d81b7fb13725",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import igraph as ig\n",
    "import json"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook options\n",
    "# Woke-quiz: hoeveel genders zijn er? Studenten hebben moeite met antwoorden: 1pWjP9QNLcg\n",
    "# Nederlandse vissers weggepest door Brussel en Den Haag: gUryIVhXHoc\n",
    "# BBB formatie loopt gesmeerd: nieuwe wind of meer van hetzelfde?: XQjBYdoiirE\n",
    "# Komt er een rechtse coalitie na val kabinet-Rutte IV?: KDnSeLGnZYI\n",
    "# Oppositie reageert op vertrek Mark Rutte uit de Nederlandse politiek: VfWUbQfzYTg\n",
    "filtering = False\n",
    "filter = 'VfWUbQfzYTg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   "id": "7d7dfccb1d7f9edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T09:17:46.447244Z",
     "start_time": "2023-11-29T09:17:46.399474Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edges_filename = 'edge_df.csv'\n",
    "edges_path = os.path.join('..', 'test_data', 'scraped-15.28 26-10-2023', edges_filename)\n",
    "\n",
    "vertex_filename = 'vertex_df.csv'\n",
    "vertex_path = os.path.join('..', 'test_data', 'scraped-15.28 26-10-2023', vertex_filename)\n",
    "\n",
    "sentiment_filename = 'author_sentiments.csv'\n",
    "sentiment_path = os.path.join('..', 'sentiment_analysis', sentiment_filename)\n",
    "\n",
    "edge_data = pd.read_csv(edges_path)\n",
    "vertex_data = pd.read_csv(vertex_path)\n",
    "sentiment_data = pd.read_csv(sentiment_path)\n",
    "\n",
    "author_id_to_integer_mapper = json.load(open(os.path.join('prepared_data', 'author_id_to_integer.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e15a8ddcbad61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T09:18:52.767489Z",
     "start_time": "2023-11-29T09:18:51.733043Z"
    },
    "collapsed": false
   },
   "source": [
    "### Prepare vertex data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 60,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_network_data = vertex_data[['author_id', 'subscriber_count', 'view_count', 'video_count']].copy()\n",
    "\n",
    "# Get the number of comments per author\n",
    "comment_counts = edge_data['author_id'].value_counts()\n",
    "vertex_network_data['comment_count'] = vertex_network_data['author_id'].map(comment_counts)\n",
    "\n",
    "# Calculate the average length of the comments for each author\n",
    "comments = edge_data[['author_id', 'text']].copy()\n",
    "comments['comment_length'] = comments['text'].apply(lambda x: len(x.split(' ')))\n",
    "comments.drop(columns=['text'], inplace=True)\n",
    "avg_comment_length = comments.groupby('author_id')['comment_length'].mean().apply(lambda y: int(y+0.5))\n",
    "vertex_network_data = vertex_network_data.merge(avg_comment_length, on='author_id', how='left')\n",
    "vertex_network_data.rename(columns={'comment_length': 'average_length_comments'}, inplace=True)\n",
<<<<<<< HEAD
    "# vertex_network_data['average_length_comments'] = vertex_network_data['author_id'].map(avg_comment_length) # there is a mistake in this line\n",
=======
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
    "\n",
    "# Adding the sentiment data\n",
    "sentiment_map = sentiment_data.set_index('data')['sentiment']\n",
    "vertex_network_data['sentiment'] = vertex_network_data['author_id'].map(sentiment_map, na_action='ignore')\n",
    "vertex_network_data['sentiment'].fillna('no sentiment', inplace=True)\n",
    "\n",
    "# Translate sentiment values\n",
    "sentiment_translator = {'no sentiment': 'no sentiment', 'Negatief': 'negative', 'Neutraal': 'neutral', 'Positief': 'positive'}\n",
    "vertex_network_data['sentiment'] = vertex_network_data['sentiment'].map(sentiment_translator)\n",
    "\n",
    "# categorize the length of the comments\n",
    "quantile1 = vertex_network_data['average_length_comments'].quantile(0.25)\n",
    "quantile3 = vertex_network_data['average_length_comments'].quantile(0.75)\n",
    "iqr = quantile3 - quantile1 # Interquartile range\n",
    "upper_fence = quantile3 + 1.5 * iqr\n",
    "\n",
    "def categorize_comment_length(length):\n",
    "    if length <= quantile1:\n",
    "        return 'short'\n",
    "    elif length <= quantile3:\n",
    "        return 'medium'\n",
    "    return 'long'\n",
    "\n",
    "vertex_network_data['comment_length_category'] = vertex_network_data['average_length_comments'].apply(categorize_comment_length)\n",
    "\n",
    "# get the total likes for each user\n",
    "likes = edge_data.groupby('author_id')['likes'].sum()\n",
    "vertex_network_data['total_likes'] = vertex_network_data['author_id'].map(likes)\n",
    "\n",
    "# changing the author ids to integers\n",
    "vertex_network_data['author_id'] = vertex_network_data['author_id'].map(author_id_to_integer_mapper)\n",
    "\n",
    "vertex_network_data.rename(columns={'author_id': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "bc2d196cda94b2e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prepare edges data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "metadata": {},
   "source": [
    "### Prepare edges data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering for video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtering:\n",
    "  edge_data = edge_data[edge_data['video_id'] == filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   "id": "76d35b90d6e30ef1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_network_data = edge_data[['author_id', 'dest_id']].copy().rename(columns={'author_id': 'source', 'dest_id': 'target'})\n",
    "\n",
    "# dropping the na values since those are comments that definitely do not have a handle\n",
    "edge_network_data.dropna(inplace=True)\n",
    "\n",
    "# calculating an edge weight based on the number of comments (interactions) between two users\n",
    "edge_weights = edge_network_data.groupby(['source', 'target']).size().reset_index(name='edge_weight') # size() computes the size of each group\n",
    "edge_network_data = edge_network_data.merge(edge_weights, on=['source', 'target'])\n",
    "\n",
    "# dropping the duplicate edges since now we have an edge weight\n",
    "edge_network_data.drop_duplicates(subset=['source', 'target'], inplace=True)\n",
    "\n",
    "# changing the author ids to integers\n",
    "edge_network_data['source'] = edge_network_data['source'].map(author_id_to_integer_mapper)\n",
    "edge_network_data['target'] = edge_network_data['target'].map(author_id_to_integer_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating graph object in igraph"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 63,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'IGRAPH D--- 324 553 -- \\n+ attr: average_length_comments (v), comment_count (v), comment_length_category (v), id (v), sentiment (v), subscriber_count (v), total_likes (v), video_count (v), view_count (v), edge_weight (e)'"
      ]
     },
     "execution_count": 93,
=======
       "'IGRAPH D--- 50 50 -- \\n+ attr: average_length_comments (v), comment_count (v), comment_length_category (v), id (v), sentiment (v), subscriber_count (v), total_likes (v), video_count (v), view_count (v), edge_weight (e)'"
      ]
     },
     "execution_count": 63,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create igraph object of the network\n",
    "\n",
    "g = ig.Graph().DataFrame(edges=edge_network_data,\n",
    "                         vertices=vertex_network_data,\n",
    "                         directed=True)\n",
    "\n",
    "all_vertices = set(vertex_network_data['id'])\n",
    "non_isolated_vertices = set(list(edge_network_data['source']) + list(edge_network_data['target']))\n",
    "\n",
    "isolated_vertices = list(all_vertices - non_isolated_vertices)\n",
    "\n",
    "g.delete_vertices(isolated_vertices)\n",
    "\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 95,
=======
   "execution_count": 64,
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the network data\n",
    "datadir = 'prepared_data'\n",
<<<<<<< HEAD
    "\n",
    "vertex_network_data.to_csv(os.path.join(datadir, 'vertex_network_data.csv'), index=False)\n",
    "edge_network_data.to_csv(os.path.join(datadir, 'edge_network_data.csv'), index=False)\n",
    "g.write_graphml(os.path.join(datadir, 'network.graphml'))"
=======
    "vertex_csv_filename = 'vertex_network_data.csv'\n",
    "edge_csv_filename = 'edge_network_data.csv'\n",
    "network_objct_filename = 'network.graphml'\n",
    "\n",
    "if filtering:\n",
    "  edge_csv_filename = 'edge_network_data_filtered' + f'_{filter}' + '.csv'\n",
    "  network_objct_filename = 'network_filtered' + f'_{filter}' + '.graphml'\n",
    "\n",
    "vertex_network_data.to_csv(os.path.join(datadir, 'vertex_network_data'), index=False) # always the same\n",
    "edge_network_data.to_csv(os.path.join(datadir, edge_csv_filename), index=False)\n",
    "g.write_graphml(os.path.join(datadir, network_objct_filename))"
>>>>>>> 2247b37ca9b1a3960e36358913aac104da4446a2
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
